{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15b3c343",
   "metadata": {},
   "source": [
    "# Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fecd2679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1027, 5)\n",
      "Train (656, 4) (656,)\n",
      "Test (206, 4) (206,)\n",
      "Validation (165, 4) (165,)\n",
      "Counter({False: 339, True: 317})\n",
      "Counter({False: 106, True: 100})\n",
      "Counter({False: 85, True: 80})\n",
      "{'weights': 'distance', 'n_neighbors': 13, 'metric': 'manhattan'}\n",
      "KNeighborsClassifier(metric='manhattan', n_neighbors=13, weights='distance')\n",
      "{'kernel': 'rbf', 'gamma': 0.0001, 'C': 100}\n",
      "SVC(C=100, gamma=0.0001)\n",
      "{'n_estimators': 150, 'max_leaf_nodes': 9, 'max_features': None, 'max_depth': 3}\n",
      "RandomForestClassifier(max_depth=3, max_features=None, max_leaf_nodes=9,\n",
      "                       n_estimators=150)\n",
      "[('LR', LogisticRegression(solver='liblinear')), ('KNN', RandomizedSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
      "                   param_distributions={'metric': ['minkowski', 'euclidean',\n",
      "                                                   'manhattan'],\n",
      "                                        'n_neighbors': [5, 7, 9, 11, 13, 15],\n",
      "                                        'weights': ['uniform', 'distance']},\n",
      "                   scoring='roc_auc')), ('DTC', DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, random_state=42)), ('SVM', RandomizedSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
      "                   param_distributions={'C': [0.1, 1, 10, 100, 1000],\n",
      "                                        'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
      "                                        'kernel': ['rbf', 'linear']},\n",
      "                   scoring='roc_auc')), ('LSVM', LinearSVC(dual=False, random_state=13)), ('RFE', RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
      "                   param_distributions={'max_depth': [3, 6, 9],\n",
      "                                        'max_features': ['sqrt', 'log2', None],\n",
      "                                        'max_leaf_nodes': [3, 6, 9],\n",
      "                                        'n_estimators': [25, 50, 100, 150]},\n",
      "                   scoring='roc_auc')), ('XGB', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)), ('Bagging', BalancedBaggingClassifier(random_state=42))]\n",
      "LR: 88.895483 (0.038766)\n",
      "KNN: 89.539327 (0.032174)\n",
      "DTC: 91.242900 (0.026063)\n",
      "SVM: 86.840736 (0.059599)\n",
      "LSVM: 89.169611 (0.037378)\n",
      "RFE: 90.662802 (0.031734)\n",
      "XGB: 86.920600 (0.036593)\n",
      "Bagging: 88.081276 (0.034183)\n",
      "Accuracy  For Test set\n",
      "Accuracy  KNN: 88.44\n",
      "Accuracy  DT: 89.22\n",
      "Accuracy  SVM: 86.70\n",
      "Accuracy  LR: 85.71\n",
      "Accuracy  LSVM: 85.28\n",
      "Accuracy  RFE: 89.76\n",
      "Accuracy  XGB: 87.88\n",
      "F1 score For Test set\n",
      "F1 score KNN: 88.44\n",
      "F1 score DT: 89.22\n",
      "F1 score SVM: 86.70\n",
      "F1 score LR: 85.71\n",
      "F1 score LSVM: 85.28\n",
      "F1 score RFE: 89.76\n",
      "F1 Score XGB: 87.88\n",
      "Precision score For Test set\n",
      "Precision KNN: 88.89\n",
      "Precision DT: 87.50\n",
      "Precision SVM: 85.44\n",
      "Precision LR: 87.50\n",
      "Precision LSVM: 86.60\n",
      "Precision RFE: 87.62\n",
      "Precision XGB: 88.78\n",
      "Recall score For Test set\n",
      "Recall KNN: 88.00\n",
      "Recall DT: 91.00\n",
      "Recall SVM: 88.00\n",
      "Recall LR: 84.00\n",
      "Recall LSVM: 84.00\n",
      "Recall RFE: 92.00\n",
      "Recall XGB: 87.00\n",
      "Accuracy  For Validation set\n",
      "Accuracy  KNN: 88.05\n",
      "Accuracy  DT: 87.95\n",
      "Accuracy  SVM: 86.96\n",
      "Accuracy  LR: 86.25\n",
      "Accuracy  LSVM: 86.79\n",
      "Accuracy  RFE: 88.48\n",
      "Accuracy  XGB: 85.90\n",
      "F1 score For Validation set\n",
      "F1 score KNN: 88.05\n",
      "F1 score DT: 87.95\n",
      "F1 score SVM: 86.96\n",
      "F1 score LR: 86.25\n",
      "F1 score LSVM: 86.79\n",
      "F1 score RFE: 88.48\n",
      "F1 Score XGB: 85.90\n",
      "Precision For Validation set\n",
      "Precision KNN: 88.61\n",
      "Precision DT: 84.88\n",
      "Precision SVM: 86.42\n",
      "Precision LR: 86.25\n",
      "Precision LSVM: 87.34\n",
      "Precision RFE: 85.88\n",
      "Precision XGB: 88.16\n",
      "Recall For Validation set\n",
      "Recall KNN: 87.50\n",
      "Recall DT: 91.25\n",
      "Recall SVM: 87.50\n",
      "Recall LR: 86.25\n",
      "Recall LSVM: 87.50\n",
      "Recall RFE: 87.50\n",
      "Recall XGB: 87.50\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load and Split data\n",
    "\n",
    "# Load dataset\n",
    "#dataset = read_csv(\"D:/Academy/thesis/machin learning part/data/inputML_Q11.csv\")\n",
    "dataset = read_csv(\"D:/Academy/thesis/machin learning part/data/inputML_Q5_with_CGGA.csv\")\n",
    "####dataset = read_csv(\"D:/Academy/thesis/machin learning part/data/inputML_random_with_CGGA.csv\")\n",
    "dataset.set_index('name', inplace=True)\n",
    "dataset['stage'].replace({'brain lower grade glioma':False, 'glioblastoma multiforme':True}, inplace=True)\n",
    "dataset[dataset.select_dtypes(['object']).columns] = dataset.select_dtypes(['object']).apply(lambda x: x.astype('category'))\n",
    "print(dataset.shape)\n",
    "\n",
    "# Split dataset\n",
    "X = dataset.drop('stage', axis=1)\n",
    "y = dataset['stage']\n",
    "x_main, x_test, y_main, y_test = train_test_split(X, y, test_size=0.20, random_state=1, stratify=y)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_main, y_main, test_size=0.20, random_state=1, stratify=y_main)\n",
    "# summarize\n",
    "print('Train', x_train.shape, y_train.shape)\n",
    "print('Test', x_test.shape, y_test.shape)\n",
    "print('Validation', x_val.shape, y_val.shape)\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_test))\n",
    "print(Counter(y_val))\n",
    "\n",
    "# Apply SMOTE\n",
    "\n",
    "#oversample = SMOTE()\n",
    "#x_train, y_train = oversample.fit_resample(x_train, y_train)\n",
    "#print(Counter(y_train))\n",
    "\n",
    "# Hyperparameter Tunning\n",
    "\n",
    "# Fitting some Models\n",
    "\n",
    "# Fitting Model\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.feature_selection import RFE\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "knn = KNeighborsClassifier()\n",
    "param_knn = {'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "\n",
    "knn = RandomizedSearchCV(estimator=knn, param_distributions=param_knn,\n",
    "                              n_iter=10, scoring='roc_auc', cv=5,\n",
    "                              refit=True, n_jobs=-1)\n",
    "knn = knn.fit(x_train, y_train)\n",
    "print(knn.best_params_)\n",
    "print(knn.best_estimator_)\n",
    "\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "dtc = DecisionTreeClassifier(criterion=\"gini\", random_state=42, max_depth=3, min_samples_leaf=5) \n",
    "dtc = dtc.fit(x_train, y_train) \n",
    "\n",
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "param_svm = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf', 'linear']}\n",
    "\n",
    "svm = RandomizedSearchCV(estimator=svm, param_distributions=param_svm,\n",
    "                              n_iter=10, scoring='roc_auc', cv=5,\n",
    "                              refit=True, n_jobs=-1)\n",
    "svm = svm.fit(x_train, y_train)\n",
    "\n",
    "print(svm.best_params_)\n",
    "print(svm.best_estimator_)\n",
    "\n",
    "# Linear SVM\n",
    "lsvm = LinearSVC(dual=False, random_state=13)\n",
    "lsvm = lsvm.fit(x_train, y_train) \n",
    "\n",
    "\n",
    "# Logestic regression\n",
    "LR = LogisticRegression(solver='liblinear')\n",
    "LR = LR.fit(x_train, y_train)\n",
    "\n",
    "#RFE\n",
    "rfe = RandomForestClassifier()\n",
    "param_rf = {'n_estimators': [25, 50, 100, 150],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'max_leaf_nodes': [3, 6, 9]}\n",
    "rfe = RandomizedSearchCV(estimator=rfe, param_distributions=param_rf,\n",
    "                              n_iter=10, scoring='roc_auc', cv=5,\n",
    "                              refit=True, n_jobs=-1)\n",
    "rfe = rfe.fit(x_train, y_train)  \n",
    "print(rfe.best_params_)\n",
    "print(rfe.best_estimator_)\n",
    "\n",
    "# XGB\n",
    "xgb = XGBClassifier(tree_method=\"hist\")\n",
    "xgb = xgb.fit(x_train, y_train) \n",
    "\n",
    "# Bagging\n",
    "classifier = BalancedBaggingClassifier(random_state=42)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# Compare different Classifiers\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "models = []\n",
    "models.append(('LR', LR))\n",
    "models.append(('KNN', knn))\n",
    "models.append(('DTC', dtc))\n",
    "models.append(('SVM', svm))\n",
    "models.append(('LSVM', lsvm))\n",
    "models.append(('RFE', rfe))\n",
    "models.append(('XGB', xgb))\n",
    "models.append(('Bagging', classifier))\n",
    "\n",
    "\n",
    "print(models)\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tcv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring='f1')#f1 roc_auc\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprint('%s: %f (%f)' % (name, cv_results.mean()*100, cv_results.std()))\n",
    "\n",
    "\n",
    "# Model Evaluation on Test  set\n",
    "\n",
    "Y_knn = knn.predict(x_test) \n",
    "Y_dtc = dtc.predict(x_test) \n",
    "Y_svm = svm.predict(x_test) \n",
    "Y_lr = LR.predict(x_test)\n",
    "Y_lsvm = lsvm.predict(x_test) \n",
    "Y_rfe = rfe.predict(x_test) \n",
    "Y_xgb = xgb.predict(x_test) \n",
    "\n",
    "# Evaluate predictions \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "print('Accuracy  For Test set')\n",
    "print('Accuracy  KNN: %.2f' % (f1_score(y_test, Y_knn)*100))\n",
    "print('Accuracy  DT: %.2f' % (f1_score(y_test, Y_dtc)*100))\n",
    "print('Accuracy  SVM: %.2f' % (f1_score(y_test, Y_svm)*100))\n",
    "print('Accuracy  LR: %.2f' % (f1_score(y_test, Y_lr)*100))\n",
    "print('Accuracy  LSVM: %.2f' % (f1_score(y_test, Y_lsvm)*100))\n",
    "print('Accuracy  RFE: %.2f' % (f1_score(y_test, Y_rfe)*100))\n",
    "print('Accuracy  XGB: %.2f' % (f1_score(y_test, Y_xgb)*100))\n",
    "\n",
    "print('F1 score For Test set')\n",
    "print('F1 score KNN: %.2f' % (f1_score(y_test, Y_knn)*100))\n",
    "print('F1 score DT: %.2f' % (f1_score(y_test, Y_dtc)*100))\n",
    "print('F1 score SVM: %.2f' % (f1_score(y_test, Y_svm)*100))\n",
    "print('F1 score LR: %.2f' % (f1_score(y_test, Y_lr)*100))\n",
    "print('F1 score LSVM: %.2f' % (f1_score(y_test, Y_lsvm)*100))\n",
    "print('F1 score RFE: %.2f' % (f1_score(y_test, Y_rfe)*100))\n",
    "print('F1 Score XGB: %.2f' % (f1_score(y_test, Y_xgb)*100))\n",
    "\n",
    "print('Precision score For Test set')\n",
    "print('Precision KNN: %.2f' % (precision_score(y_test, Y_knn)*100))\n",
    "print('Precision DT: %.2f' % (precision_score(y_test, Y_dtc)*100))\n",
    "print('Precision SVM: %.2f' % (precision_score(y_test, Y_svm)*100))\n",
    "print('Precision LR: %.2f' % (precision_score(y_test, Y_lr)*100))\n",
    "print('Precision LSVM: %.2f' % (precision_score(y_test, Y_lsvm)*100))\n",
    "print('Precision RFE: %.2f' % (precision_score(y_test, Y_rfe)*100))\n",
    "print('Precision XGB: %.2f' % (precision_score(y_test, Y_xgb)*100))\n",
    "\n",
    "\n",
    "print('Recall score For Test set')\n",
    "print('Recall KNN: %.2f' % (recall_score(y_test, Y_knn)*100))\n",
    "print('Recall DT: %.2f' % (recall_score(y_test, Y_dtc)*100))\n",
    "print('Recall SVM: %.2f' % (recall_score(y_test, Y_svm)*100))\n",
    "print('Recall LR: %.2f' % (recall_score(y_test, Y_lr)*100))\n",
    "print('Recall LSVM: %.2f' % (recall_score(y_test, Y_lsvm)*100))\n",
    "print('Recall RFE: %.2f' % (recall_score(y_test, Y_rfe)*100))\n",
    "print('Recall XGB: %.2f' % (recall_score(y_test, Y_xgb)*100))\n",
    "\n",
    "#print(confusion_matrix(y_test, Y_rfe))\n",
    "#print(classification_report(y_test, Y_knn))\n",
    "#accuracy_score\n",
    "# roc_auc_score\n",
    "\n",
    "\n",
    "# Model Evaluation on Validation set\n",
    "\n",
    "Y_knn_val = knn.predict(x_val) \n",
    "Y_dtc_val = dtc.predict(x_val) \n",
    "Y_svm_val = svm.predict(x_val) \n",
    "Y_lr_val = LR.predict(x_val) \n",
    "Y_lsvm_val = lsvm.predict(x_val) \n",
    "Y_rfe_val = rfe.predict(x_val)\n",
    "Y_xgb_val = xgb.predict(x_val) \n",
    "\n",
    "\n",
    "# Evaluate predictions \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy  For Validation set')\n",
    "print('Accuracy  KNN: %.2f' % (f1_score(y_val, Y_knn_val)*100))\n",
    "print('Accuracy  DT: %.2f' % (f1_score(y_val, Y_dtc_val)*100))\n",
    "print('Accuracy  SVM: %.2f' % (f1_score(y_val, Y_svm_val)*100))\n",
    "print('Accuracy  LR: %.2f' % (f1_score(y_val, Y_lr_val)*100))\n",
    "print('Accuracy  LSVM: %.2f' % (f1_score(y_val, Y_lsvm_val)*100))\n",
    "print('Accuracy  RFE: %.2f' % (f1_score(y_val, Y_rfe_val)*100))\n",
    "print('Accuracy  XGB: %.2f' % (f1_score(y_val, Y_xgb_val)*100))\n",
    "\n",
    "print('F1 score For Validation set')\n",
    "print('F1 score KNN: %.2f' % (f1_score(y_val, Y_knn_val)*100))\n",
    "print('F1 score DT: %.2f' % (f1_score(y_val, Y_dtc_val)*100))\n",
    "print('F1 score SVM: %.2f' % (f1_score(y_val, Y_svm_val)*100))\n",
    "print('F1 score LR: %.2f' % (f1_score(y_val, Y_lr_val)*100))\n",
    "print('F1 score LSVM: %.2f' % (f1_score(y_val, Y_lsvm_val)*100))\n",
    "print('F1 score RFE: %.2f' % (f1_score(y_val, Y_rfe_val)*100))\n",
    "print('F1 Score XGB: %.2f' % (f1_score(y_val, Y_xgb_val)*100))\n",
    "\n",
    "print('Precision For Validation set')\n",
    "print('Precision KNN: %.2f' % (precision_score(y_val, Y_knn_val)*100))\n",
    "print('Precision DT: %.2f' % (precision_score(y_val, Y_dtc_val)*100))\n",
    "print('Precision SVM: %.2f' % (precision_score(y_val, Y_svm_val)*100))\n",
    "print('Precision LR: %.2f' % (precision_score(y_val, Y_lr_val)*100))\n",
    "print('Precision LSVM: %.2f' % (precision_score(y_val, Y_lsvm_val)*100))\n",
    "print('Precision RFE: %.2f' % (precision_score(y_val, Y_rfe_val)*100))\n",
    "print('Precision XGB: %.2f' % (precision_score(y_val, Y_xgb_val)*100))\n",
    "\n",
    "\n",
    "print('Recall For Validation set')\n",
    "print('Recall KNN: %.2f' % (recall_score(y_val, Y_knn_val)*100))\n",
    "print('Recall DT: %.2f' % (recall_score(y_val, Y_dtc_val)*100))\n",
    "print('Recall SVM: %.2f' % (recall_score(y_val, Y_svm_val)*100))\n",
    "print('Recall LR: %.2f' % (recall_score(y_val, Y_lr_val)*100))\n",
    "print('Recall LSVM: %.2f' % (recall_score(y_val, Y_knn_val)*100))\n",
    "print('Recall RFE: %.2f' % (recall_score(y_val, Y_knn_val)*100))\n",
    "print('Recall XGB: %.2f' % (recall_score(y_val, Y_knn_val)*100))\n",
    "\n",
    "#print(confusion_matrix(y_val, Y_rfe_val))\n",
    "#print(classification_report(y_test, Y_svm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c75506",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
